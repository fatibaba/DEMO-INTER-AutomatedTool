{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76b500c-29b2-4e90-b5e9-6cb74d5e9ae8",
   "metadata": {},
   "source": [
    "# DEMO-INTER-AutomatedTool (Jupyter Notebook)\n",
    "\n",
    "This notebook provides a step-by-step guide for automatically matching ontology classes.  \n",
    "It allows you to:\n",
    "- Load an ontology from a URL or a local file.\n",
    "- Extract and compare ontology class IRIs, labels, synonyms, and definitions.\n",
    "- Display matches in a table and download the results as a CSV.\n",
    "\n",
    "**Getting Started:**\n",
    "Run the cells below in sequence, following the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e40c14-6234-4c27-b436-93273eeaac63",
   "metadata": {},
   "source": [
    "## find matching class IRIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27c20c5-2e30-4c22-975d-2138ec78a9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (7.0.0)\n",
      "Requirement already satisfied: requests in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from rdflib) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six in /Users/fatimababa/miniconda3/envs/BR_UK/lib/python3.12/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
      "Choose an option for the first ontology:\n",
      "1: Provide a URL\n",
      "2: Provide a file path\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  1\n",
      "Enter the URL of the first ontology:  https://raw.githubusercontent.com/HumanBehaviourChangeProject/ontologies/refs/heads/master/Behaviour/bcio_behaviour.owl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully fetched ontology from: https://raw.githubusercontent.com/HumanBehaviourChangeProject/ontologies/refs/heads/master/Behaviour/bcio_behaviour.owl\n",
      "\n",
      "Choose an option for the second ontology:\n",
      "1: Provide a URL\n",
      "2: Provide a file path\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  2\n",
      "Enter the path to the second ontology file:  copper2.rdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded ontology from local file: copper2.rdf\n",
      "\n",
      "üîç Total common class IRIs found: 5\n",
      "\n",
      "‚úÖ Matching class IRIs have been saved to: matching_IRIs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Class IRI</th>\n",
       "      <th>Label in Ontology 1</th>\n",
       "      <th>Label in Ontology 2</th>\n",
       "      <th>Definition in Ontology 1</th>\n",
       "      <th>Definition in Ontology 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>http://humanbehaviourchange.org/ontology/BCIO_050300</td>\n",
       "      <td>personal attribute</td>\n",
       "      <td>personal attribute</td>\n",
       "      <td>A specifically dependent continuant that inheres in a person.</td>\n",
       "      <td>A specifically dependent continuant that inheres in a person.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http://humanbehaviourchange.org/ontology/BCIO_036042</td>\n",
       "      <td>physical performance behaviour</td>\n",
       "      <td>physical performance behaviour</td>\n",
       "      <td>A health-related behaviour that involves maintenance or improvement of flexibility, strength, balance or cardiovascular fitness.</td>\n",
       "      <td>A life enhancement behaviour that has a physical fitness function.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http://purl.obolibrary.org/obo/MF_0000016</td>\n",
       "      <td>(no label)</td>\n",
       "      <td>person</td>\n",
       "      <td>(no definition)</td>\n",
       "      <td>A member of the species Homo Sapiens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http://humanbehaviourchange.org/ontology/BCIO_006085</td>\n",
       "      <td>location</td>\n",
       "      <td>Location</td>\n",
       "      <td>A spatial &lt;quality&gt; that inheres in a bearer by virtue of its position relative to other entities.</td>\n",
       "      <td>A spatial quality that inheres in a bearer by virtue of its position relative to other entities.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http://humanbehaviourchange.org/ontology/BCIO_006099</td>\n",
       "      <td>social influence behaviour</td>\n",
       "      <td>social influence behaviour</td>\n",
       "      <td>An &lt;inter-personal behaviour&gt; where a person exerts an influence on the behaviour of another.</td>\n",
       "      <td>An inter-personal behaviour where a person exerts an influence on the behaviour of another.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"data:file/csv;base64,Q2xhc3MgSVJJLExhYmVsIGluIE9udG9sb2d5IDEsTGFiZWwgaW4gT250b2xvZ3kgMixEZWZpbml0aW9uIGluIE9udG9sb2d5IDEsRGVmaW5pdGlvbiBpbiBPbnRvbG9neSAyCmh0dHA6Ly9odW1hbmJlaGF2aW91cmNoYW5nZS5vcmcvb250b2xvZ3kvQkNJT18wNTAzMDAscGVyc29uYWwgYXR0cmlidXRlLHBlcnNvbmFsIGF0dHJpYnV0ZSxBIHNwZWNpZmljYWxseSBkZXBlbmRlbnQgY29udGludWFudCB0aGF0IGluaGVyZXMgaW4gYSBwZXJzb24uLEEgc3BlY2lmaWNhbGx5IGRlcGVuZGVudCBjb250aW51YW50IHRoYXQgaW5oZXJlcyBpbiBhIHBlcnNvbi4KaHR0cDovL2h1bWFuYmVoYXZpb3VyY2hhbmdlLm9yZy9vbnRvbG9neS9CQ0lPXzAzNjA0MixwaHlzaWNhbCBwZXJmb3JtYW5jZSBiZWhhdmlvdXIscGh5c2ljYWwgcGVyZm9ybWFuY2UgYmVoYXZpb3VyLCJBIGhlYWx0aC1yZWxhdGVkIGJlaGF2aW91ciB0aGF0IGludm9sdmVzIG1haW50ZW5hbmNlIG9yIGltcHJvdmVtZW50IG9mIGZsZXhpYmlsaXR5LCBzdHJlbmd0aCwgYmFsYW5jZSBvciBjYXJkaW92YXNjdWxhciBmaXRuZXNzLiIsQSBsaWZlIGVuaGFuY2VtZW50IGJlaGF2aW91ciB0aGF0IGhhcyBhIHBoeXNpY2FsIGZpdG5lc3MgZnVuY3Rpb24uCmh0dHA6Ly9wdXJsLm9ib2xpYnJhcnkub3JnL29iby9NRl8wMDAwMDE2LChubyBsYWJlbCkscGVyc29uLChubyBkZWZpbml0aW9uKSxBIG1lbWJlciBvZiB0aGUgc3BlY2llcyBIb21vIFNhcGllbnMuCmh0dHA6Ly9odW1hbmJlaGF2aW91cmNoYW5nZS5vcmcvb250b2xvZ3kvQkNJT18wMDYwODUsbG9jYXRpb24sTG9jYXRpb24sQSBzcGF0aWFsIDxxdWFsaXR5PiB0aGF0IGluaGVyZXMgaW4gYSBiZWFyZXIgYnkgdmlydHVlIG9mIGl0cyBwb3NpdGlvbiByZWxhdGl2ZSB0byBvdGhlciBlbnRpdGllcy4sQSBzcGF0aWFsIHF1YWxpdHkgdGhhdCBpbmhlcmVzIGluIGEgYmVhcmVyIGJ5IHZpcnR1ZSBvZiBpdHMgcG9zaXRpb24gcmVsYXRpdmUgdG8gb3RoZXIgZW50aXRpZXMuCmh0dHA6Ly9odW1hbmJlaGF2aW91cmNoYW5nZS5vcmcvb250b2xvZ3kvQkNJT18wMDYwOTksc29jaWFsIGluZmx1ZW5jZSBiZWhhdmlvdXIsc29jaWFsIGluZmx1ZW5jZSBiZWhhdmlvdXIsQW4gPGludGVyLXBlcnNvbmFsIGJlaGF2aW91cj4gd2hlcmUgYSBwZXJzb24gZXhlcnRzIGFuIGluZmx1ZW5jZSBvbiB0aGUgYmVoYXZpb3VyIG9mIGFub3RoZXIuLEFuIGludGVyLXBlcnNvbmFsIGJlaGF2aW91ciB3aGVyZSBhIHBlcnNvbiBleGVydHMgYW4gaW5mbHVlbmNlIG9uIHRoZSBiZWhhdmlvdXIgb2YgYW5vdGhlci4K\" download=\"matching_IRIs.csv\">Download CSV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following line if you need to install packages in your Notebook\n",
    "!pip install rdflib requests pandas\n",
    "\n",
    "import io\n",
    "import base64\n",
    "import csv\n",
    "import requests\n",
    "import rdflib\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def load_ontology_from_url(ontology_url):\n",
    "    \"\"\"\n",
    "    Fetches an ontology file from a URL and loads it into an RDF graph.\n",
    "    \"\"\"\n",
    "    response = requests.get(ontology_url)\n",
    "    if response.status_code == 200:\n",
    "        graph = Graph()\n",
    "        graph.parse(data=response.text, format=\"xml\")\n",
    "        print(f\"‚úÖ Successfully fetched ontology from: {ontology_url}\")\n",
    "        return graph\n",
    "    else:\n",
    "        raise Exception(f\"‚ùå Error fetching ontology from {ontology_url}: {response.status_code}\")\n",
    "\n",
    "def load_ontology_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads an ontology file from a local file path.\n",
    "    \"\"\"\n",
    "    graph = Graph()\n",
    "    graph.parse(file_path, format=\"xml\")\n",
    "    print(f\"‚úÖ Successfully loaded ontology from local file: {file_path}\")\n",
    "    return graph\n",
    "\n",
    "def extract_filtered_classes(graph, excluded_base_uris):\n",
    "    \"\"\"\n",
    "    Extracts class IRIs, labels, and definitions from the ontology while filtering out upper-level ontology classes.\n",
    "    \"\"\"\n",
    "    excluded_filters = \" || \".join(\n",
    "        [f\"STRSTARTS(STR(?class), '{base_uri}')\" for base_uri in excluded_base_uris]\n",
    "    )\n",
    "    query = f\"\"\"\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX iao: <http://purl.obolibrary.org/obo/IAO_>\n",
    "\n",
    "    SELECT DISTINCT ?class ?label ?definition WHERE {{\n",
    "        ?class a owl:Class .\n",
    "        OPTIONAL {{ ?class rdfs:label ?label . }}\n",
    "        OPTIONAL {{ ?class iao:0000115 ?definition . }}\n",
    "        OPTIONAL {{ ?class rdfs:definition ?definition . }}\n",
    "        FILTER (!({excluded_filters}))  # Exclude specified base URIs\n",
    "    }}\n",
    "    \"\"\"\n",
    "    results = graph.query(query)\n",
    "    return {\n",
    "        str(row[\"class\"]): {\n",
    "            \"label\": str(row[\"label\"]) if row[\"label\"] else \"(no label)\",\n",
    "            \"definition\": str(row[\"definition\"]) if row[\"definition\"] else \"(no definition)\",\n",
    "        }\n",
    "        for row in results\n",
    "    }\n",
    "\n",
    "def find_common_class_iris(classes1, classes2):\n",
    "    \"\"\"\n",
    "    Identifies common class IRIs between two ontologies.\n",
    "    \"\"\"\n",
    "    return set(classes1.keys()).intersection(set(classes2.keys()))\n",
    "\n",
    "def save_results_to_csv(common_class_iris, classes1, classes2, filename='matching_IRIs.csv'):\n",
    "    \"\"\"\n",
    "    Saves common class IRIs, labels, and definitions to a CSV file and provides a download link.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'Class IRI': iri,\n",
    "            'Label in Ontology 1': classes1[iri]['label'],\n",
    "            'Label in Ontology 2': classes2[iri]['label'],\n",
    "            'Definition in Ontology 1': classes1[iri]['definition'],\n",
    "            'Definition in Ontology 2': classes2[iri]['definition']\n",
    "        }\n",
    "        for iri in common_class_iris\n",
    "    ])\n",
    "    \n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Matching class IRIs have been saved to: {filename}\")\n",
    "    \n",
    "    # Display the results as a table in the Notebook\n",
    "    display(HTML(df.to_html(index=False)))\n",
    "\n",
    "    # Provide a download link for the CSV file\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"{filename}\">Download CSV</a>'\n",
    "    display(HTML(href))\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "print(\"Choose an option for the first ontology:\")\n",
    "print(\"1: Provide a URL\")\n",
    "print(\"2: Provide a file path\")\n",
    "option1 = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "if option1 == \"1\":\n",
    "    ontology_url1 = input(\"Enter the URL of the first ontology: \").strip()\n",
    "    ontology1 = load_ontology_from_url(ontology_url1)\n",
    "elif option1 == \"2\":\n",
    "    file_path1 = input(\"Enter the path to the first ontology file: \").strip()\n",
    "    ontology1 = load_ontology_from_file(file_path1)\n",
    "else:\n",
    "    raise Exception(\"‚ùå Invalid selection. Please enter either 1 or 2.\")\n",
    "\n",
    "print(\"\\nChoose an option for the second ontology:\")\n",
    "print(\"1: Provide a URL\")\n",
    "print(\"2: Provide a file path\")\n",
    "option2 = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "if option2 == \"1\":\n",
    "    ontology_url2 = input(\"Enter the URL of the second ontology: \").strip()\n",
    "    ontology2 = load_ontology_from_url(ontology_url2)\n",
    "elif option2 == \"2\":\n",
    "    file_path2 = input(\"Enter the path to the second ontology file: \").strip()\n",
    "    ontology2 = load_ontology_from_file(file_path2)\n",
    "else:\n",
    "    raise Exception(\"‚ùå Invalid selection. Please enter either 1 or 2.\")\n",
    "\n",
    "# Define base URIs to exclude (e.g., upper-level ontology classes)\n",
    "excluded_base_uris = [\n",
    "    \"http://purl.obolibrary.org/obo/IAO_\",\n",
    "    \"http://purl.obolibrary.org/obo/BFO_\"\n",
    "]\n",
    "\n",
    "# Extract class details while filtering out excluded base URIs\n",
    "classes1 = extract_filtered_classes(ontology1, excluded_base_uris)\n",
    "classes2 = extract_filtered_classes(ontology2, excluded_base_uris)\n",
    "\n",
    "# Identify common class IRIs\n",
    "common_class_iris = find_common_class_iris(classes1, classes2)\n",
    "\n",
    "# Display the number of common class IRIs found\n",
    "print(f\"\\nüîç Total common class IRIs found: {len(common_class_iris)}\")\n",
    "\n",
    "# Save results to CSV, display results in a table, and provide a download link\n",
    "if common_class_iris:\n",
    "    save_results_to_csv(common_class_iris, classes1, classes2, filename=\"matching_IRIs.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No common class IRIs found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1234d8-e5b5-4249-96d6-856faed8d9b7",
   "metadata": {},
   "source": [
    "## Compare two ontologies and identify synonyms or the same labels where class IRIs are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27381b5-a5ce-46cf-96db-d0e62f41f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option for the first ontology:\n",
      "1: Provide a URL\n",
      "2: Provide a file path\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  1\n",
      "Enter the URL of the first ontology:  https://raw.githubusercontent.com/HumanBehaviourChangeProject/ontologies/refs/heads/master/Behaviour/bcio_behaviour.owl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully fetched ontology from: https://raw.githubusercontent.com/HumanBehaviourChangeProject/ontologies/refs/heads/master/Behaviour/bcio_behaviour.owl\n",
      "\n",
      "Choose an option for the second ontology:\n",
      "1: Provide a URL\n",
      "2: Provide a file path\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  2\n",
      "Enter the path to the second ontology file:  copper2.rdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded ontology from local file: copper2.rdf\n",
      "\n",
      "üîç Number of matching class labels/synonyms found: 1\n",
      "\n",
      "‚úÖ Matching classes have been saved to: matching_classes.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ontology 1 Class URI</th>\n",
       "      <th>Ontology 1 Class Label</th>\n",
       "      <th>Ontology 1 Class Definition</th>\n",
       "      <th>Ontology 2 Class URI</th>\n",
       "      <th>Ontology 2 Class Label</th>\n",
       "      <th>Ontology 2 Class Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>http://humanbehaviourchange.org/ontology/BCIO_036108</td>\n",
       "      <td>walking</td>\n",
       "      <td>A locomotive behaviour that involves moving at a regular pace by lifting and setting down each foot in turn, never having both feet off the ground at once.</td>\n",
       "      <td>http://COPPER/ontology/COPPER_1020</td>\n",
       "      <td>Walking</td>\n",
       "      <td>A physical performance behaviour that involves moving at a regular pace by lifting and setting down each foot in turn, never having both feet off the ground at once.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"data:file/csv;base64,T250b2xvZ3kgMSBDbGFzcyBVUkksT250b2xvZ3kgMSBDbGFzcyBMYWJlbCxPbnRvbG9neSAxIENsYXNzIERlZmluaXRpb24sT250b2xvZ3kgMiBDbGFzcyBVUkksT250b2xvZ3kgMiBDbGFzcyBMYWJlbCxPbnRvbG9neSAyIENsYXNzIERlZmluaXRpb24KaHR0cDovL2h1bWFuYmVoYXZpb3VyY2hhbmdlLm9yZy9vbnRvbG9neS9CQ0lPXzAzNjEwOCx3YWxraW5nLCJBIGxvY29tb3RpdmUgYmVoYXZpb3VyIHRoYXQgaW52b2x2ZXMgbW92aW5nIGF0IGEgcmVndWxhciBwYWNlIGJ5IGxpZnRpbmcgYW5kIHNldHRpbmcgZG93biBlYWNoIGZvb3QgaW4gdHVybiwgbmV2ZXIgaGF2aW5nIGJvdGggZmVldCBvZmYgdGhlIGdyb3VuZCBhdCBvbmNlLiIsaHR0cDovL0NPUFBFUi9vbnRvbG9neS9DT1BQRVJfMTAyMCxXYWxraW5nLCJBIHBoeXNpY2FsIHBlcmZvcm1hbmNlIGJlaGF2aW91ciB0aGF0IGludm9sdmVzIG1vdmluZyBhdCBhIHJlZ3VsYXIgcGFjZSBieSBsaWZ0aW5nIGFuZCBzZXR0aW5nIGRvd24gZWFjaCBmb290IGluIHR1cm4sIG5ldmVyIGhhdmluZyBib3RoIGZlZXQgb2ZmIHRoZSBncm91bmQgYXQgb25jZS4iCg==\" download=\"matching_classes.csv\">Download CSV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following line if you need to install packages in your Notebook\n",
    "# !pip install rdflib requests pandas\n",
    "\n",
    "import io\n",
    "import base64\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import rdflib\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def load_ontology_from_url(ontology_url):\n",
    "    \"\"\"\n",
    "    Fetches an ontology file from a URL and loads it into an RDF graph.\n",
    "    \"\"\"\n",
    "    response = requests.get(ontology_url)\n",
    "    if response.status_code == 200:\n",
    "        graph = Graph()\n",
    "        graph.parse(data=response.text, format=\"xml\")\n",
    "        print(f\"‚úÖ Successfully fetched ontology from: {ontology_url}\")\n",
    "        return graph\n",
    "    else:\n",
    "        raise Exception(f\"‚ùå Error fetching ontology from {ontology_url}: {response.status_code}\")\n",
    "\n",
    "def load_ontology_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads an ontology file from a local file path.\n",
    "    \"\"\"\n",
    "    graph = Graph()\n",
    "    graph.parse(file_path, format=\"xml\")\n",
    "    print(f\"‚úÖ Successfully loaded ontology from local file: {file_path}\")\n",
    "    return graph\n",
    "\n",
    "def extract_class_details(graph):\n",
    "    \"\"\"\n",
    "    Extracts class labels, synonyms, and definitions from the ontology.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX iao: <http://purl.obolibrary.org/obo/IAO_>\n",
    "    PREFIX go: <http://www.geneontology.org/formats/oboInOwl#>\n",
    "\n",
    "    SELECT ?class ?label ?synonym ?definition\n",
    "    WHERE {\n",
    "        ?class a owl:Class .\n",
    "        OPTIONAL { ?class rdfs:label ?label . }\n",
    "        OPTIONAL { ?class iao:0000115 ?definition . }\n",
    "        OPTIONAL { ?class rdfs:definition ?definition . }\n",
    "        OPTIONAL { ?class go:hasBroadSynonym ?synonym . }    \n",
    "        OPTIONAL { ?class go:hasNarrowSynonym ?synonym . }    \n",
    "        OPTIONAL { ?class go:hasExactSynonym ?synonym . }    \n",
    "        OPTIONAL { ?class go:hasRelatedSynonym ?synonym . }    \n",
    "    }\n",
    "    \"\"\"\n",
    "    results = graph.query(query)\n",
    "    class_info = {}\n",
    "\n",
    "    # Store extracted ontology class details in a dictionary\n",
    "    for row in results:\n",
    "        class_uri = str(row['class'])\n",
    "        label = str(row['label']) if row['label'] else None\n",
    "        synonym = str(row['synonym']) if row['synonym'] else None\n",
    "        definition = str(row['definition']) if row['definition'] else None\n",
    "\n",
    "        if class_uri not in class_info:\n",
    "            class_info[class_uri] = {'label': label, 'synonyms': set(), 'definition': definition}\n",
    "\n",
    "        # Store synonyms as a lowercase set for case-insensitive matching\n",
    "        if synonym:\n",
    "            class_info[class_uri]['synonyms'].add(synonym.lower())\n",
    "\n",
    "    return class_info\n",
    "\n",
    "def find_matching_classes(classes1, classes2):\n",
    "    \"\"\"\n",
    "    Compares classes between two ontologies based on labels and synonyms to find matches.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for uri1, info1 in classes1.items():\n",
    "        for uri2, info2 in classes2.items():\n",
    "            if uri1 == uri2:\n",
    "                continue  # Skip identical class URIs, as they are already matched\n",
    "\n",
    "            # Check if labels match exactly\n",
    "            if info1['label'] and info2['label'] and info1['label'].lower() == info2['label'].lower():\n",
    "                matches.append((uri1, info1['label'], info1['definition'], uri2, info2['label'], info2['definition']))\n",
    "\n",
    "            # Check if label in one ontology appears as a synonym in the other\n",
    "            elif info1['label'] and info2['synonyms'] and info1['label'].lower() in info2['synonyms']:\n",
    "                matches.append((uri1, info1['label'], info1['definition'], uri2, info2['label'], info2['definition']))\n",
    "\n",
    "            elif info2['label'] and info1['synonyms'] and info2['label'].lower() in info1['synonyms']:\n",
    "                matches.append((uri1, info1['label'], info1['definition'], uri2, info2['label'], info2['definition']))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def save_matches_to_csv(matching_classes, filename='matching_classes.csv'):\n",
    "    \"\"\"\n",
    "    Saves matching classes to a CSV file and provides a download link.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(matching_classes, columns=[\n",
    "        'Ontology 1 Class URI', 'Ontology 1 Class Label', 'Ontology 1 Class Definition',\n",
    "        'Ontology 2 Class URI', 'Ontology 2 Class Label', 'Ontology 2 Class Definition'\n",
    "    ])\n",
    "    \n",
    "    # Save matches to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Matching classes have been saved to: {filename}\")\n",
    "\n",
    "    # Display the matches as an interactive table in the Notebook\n",
    "    display(HTML(df.to_html(index=False)))\n",
    "\n",
    "    # Provide a download link for the CSV file\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"{filename}\">Download CSV</a>'\n",
    "    display(HTML(href))\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "print(\"Choose an option for the first ontology:\")\n",
    "print(\"1: Provide a URL\")\n",
    "print(\"2: Provide a file path\")\n",
    "option1 = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "if option1 == \"1\":\n",
    "    ontology_url1 = input(\"Enter the URL of the first ontology: \").strip()\n",
    "    ontology1 = load_ontology_from_url(ontology_url1)\n",
    "elif option1 == \"2\":\n",
    "    file_path1 = input(\"Enter the path to the first ontology file: \").strip()\n",
    "    ontology1 = load_ontology_from_file(file_path1)\n",
    "else:\n",
    "    raise Exception(\"‚ùå Invalid selection. Please enter either 1 or 2.\")\n",
    "\n",
    "print(\"\\nChoose an option for the second ontology:\")\n",
    "print(\"1: Provide a URL\")\n",
    "print(\"2: Provide a file path\")\n",
    "option2 = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "if option2 == \"1\":\n",
    "    ontology_url2 = input(\"Enter the URL of the second ontology: \").strip()\n",
    "    ontology2 = load_ontology_from_url(ontology_url2)\n",
    "elif option2 == \"2\":\n",
    "    file_path2 = input(\"Enter the path to the second ontology file: \").strip()\n",
    "    ontology2 = load_ontology_from_file(file_path2)\n",
    "else:\n",
    "    raise Exception(\"‚ùå Invalid selection. Please enter either 1 or 2.\")\n",
    "\n",
    "# Extract class details from both ontologies\n",
    "classes1 = extract_class_details(ontology1)\n",
    "classes2 = extract_class_details(ontology2)\n",
    "\n",
    "# Find matching classes between the two ontologies\n",
    "matching_classes = find_matching_classes(classes1, classes2)\n",
    "\n",
    "# Display the number of matches found\n",
    "print(f\"\\nüîç Number of matching class labels/synonyms found: {len(matching_classes)}\")\n",
    "\n",
    "# Save results to CSV, display results as a table, and provide a download link\n",
    "save_matches_to_csv(matching_classes, filename=\"matching_labelsSynonyms.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03b8e2-735e-46d2-ad8d-be4f7ae2edc5",
   "metadata": {},
   "source": [
    "# find matching definitions for target classes using language model\n",
    "This script automates the process of identifying semantically similar class definitions between a list of target classes provided in a CSV file and class definitions extracted from an ontology file. It uses a combination of techniques: semantic pre-filtering with cosine similarity and prompt-based evaluation using a LLaMA language model. The output is provided as a longlist for human review. This tool:\n",
    "‚úÖ Allows users to provide ontology files via URL or file upload\n",
    "‚úÖ Uses a language model to compare definitions\n",
    "‚úÖ Applies pre-filtering using cosine similarity\n",
    "‚úÖ Displays results in a table and provides a download link for a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c89621-5053-43ab-8c51-3863f5fe722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from rdflib import Graph\n",
    "from mlx_lm import load, generate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Try to import IPython.display for a clickable download link in a notebook.\n",
    "try:\n",
    "    from IPython.display import display, HTML\n",
    "    NOTEBOOK = True\n",
    "except ImportError:\n",
    "    NOTEBOOK = False\n",
    "\n",
    "SYSTEM_MSG = \"You are an ontology expert.\"\n",
    "\n",
    "def generateFromPrompt(promptStr, model, tokenizer, maxTokens=50):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": promptStr}\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    prompt = tokenizer.decode(input_ids)\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = generate(model, tokenizer, prompt=prompt, max_tokens=maxTokens)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return response, elapsed_time\n",
    "\n",
    "def extract_class_definitions(source, base_iri):\n",
    "    g = Graph()\n",
    "    # If the source is a URL, fetch it via requests; otherwise treat it as a local file path.\n",
    "    if source.startswith(\"http\"):\n",
    "        response = requests.get(source)\n",
    "        if response.status_code == 200:\n",
    "            g.parse(data=response.text, format=\"xml\")\n",
    "        else:\n",
    "            raise Exception(f\"Failed to load ontology from URL: {source}\")\n",
    "    else:\n",
    "        g.parse(source)\n",
    "    query = f\"\"\"\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX iao: <http://purl.obolibrary.org/obo/IAO_>\n",
    "\n",
    "    SELECT ?class ?label ?definition\n",
    "    WHERE {{\n",
    "        ?class a owl:Class .\n",
    "        ?class rdfs:label ?label .\n",
    "        OPTIONAL {{ ?class iao:0000115 ?definition . }}\n",
    "        OPTIONAL {{ ?class rdfs:definition ?definition . }}\n",
    "        FILTER (STRSTARTS(str(?class), \"{base_iri}\"))\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    class_definitions = []\n",
    "    for row in g.query(query):\n",
    "        class_definitions.append({\n",
    "            'class_uri': str(row['class']),\n",
    "            'label': str(row['label']),\n",
    "            'definition': str(row.get('definition', 'No definition provided'))\n",
    "        })\n",
    "    return class_definitions\n",
    "\n",
    "def prefilter_classes(target, defs, embedder, threshold=0.5):\n",
    "    target_label = target['label'].lower()\n",
    "    target_uri = target['class_uri']\n",
    "    target_definition = target['definition']\n",
    "\n",
    "    target_synonyms = set()  # Add synonyms if needed\n",
    "\n",
    "    # Compute embedding for target definition\n",
    "    target_embedding = embedder.encode(target_definition)\n",
    "\n",
    "    candidates = []\n",
    "    for def_ in defs:\n",
    "        if def_['class_uri'] == target_uri:\n",
    "            continue\n",
    "        if def_['label'] and def_['label'].lower() == target_label:\n",
    "            continue\n",
    "        if def_['label'].lower() in target_synonyms:\n",
    "            continue\n",
    "\n",
    "        compared_embedding = embedder.encode(def_['definition'])\n",
    "        similarity = cosine_similarity([target_embedding], [compared_embedding])[0][0]\n",
    "        if similarity > threshold:\n",
    "            candidates.append(def_)\n",
    "    return candidates\n",
    "\n",
    "def create_prompt_for_class(target_class, defs):\n",
    "    prompts = []\n",
    "    for def_ in defs:\n",
    "        prompt = f\"\"\"Target Label: {target_class['label']}\n",
    "Target Definition: {target_class['definition']}\n",
    "Compared Label: {def_['label']}\n",
    "Compared Definition: {def_['definition']}\n",
    "Same meaning? (yes/no)\"\"\"\n",
    "        prompts.append((prompt, target_class, def_))\n",
    "    return prompts\n",
    "\n",
    "def process_prompts(prompts, model, tokenizer):\n",
    "    total_elapsed_time = 0\n",
    "    similar_matches = []\n",
    "    for prompt, target_class, compared_class in prompts:\n",
    "        response, elapsed_time = generateFromPrompt(prompt, model, tokenizer, maxTokens=50)\n",
    "        total_elapsed_time += elapsed_time\n",
    "        if \"yes\" in response.lower():\n",
    "            similar_matches.append((target_class, compared_class))\n",
    "    print(f\"Total time to generate all responses: {total_elapsed_time:.2f} seconds\")\n",
    "    return similar_matches\n",
    "\n",
    "def write_results_to_csv(matches, filename='matching_definitions.csv'):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['HBO Class IRI', 'HBO Class Label', 'HBO Class Definition',\n",
    "                         'COPPER Class IRI', 'COPPER Class Label', 'COPPER Class Definition'])\n",
    "        for target, match in matches:\n",
    "            writer.writerow([target['class_uri'], target['label'], target['definition'],\n",
    "                             match['class_uri'], match['label'], match['definition']])\n",
    "    print(f\"‚úÖ Results saved to: {filename}\")\n",
    "\n",
    "def read_target_classes_from_csv(filename):\n",
    "    target_classes = []\n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        print(f\"CSV Headers: {reader.fieldnames}\")\n",
    "        for row in reader:\n",
    "            target_classes.append({\n",
    "                'class_uri': row['IRI'],\n",
    "                'label': row['\\ufeffLabel'],\n",
    "                'definition': row['Definition']\n",
    "            })\n",
    "    return target_classes\n",
    "\n",
    "def display_results_table(matches):\n",
    "    data = []\n",
    "    for target, match in matches:\n",
    "        data.append({\n",
    "            \"HBO Class IRI\": target['class_uri'],\n",
    "            \"HBO Class Label\": target['label'],\n",
    "            \"HBO Class Definition\": target['definition'],\n",
    "            \"COPPER Class IRI\": match['class_uri'],\n",
    "            \"COPPER Class Label\": match['label'],\n",
    "            \"COPPER Class Definition\": match['definition']\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    # Display as an HTML table in the Notebook\n",
    "    display(HTML(df.to_html(index=False)))\n",
    "    return df\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the model and the embedding model\n",
    "    model_name = \"mlx-community/Meta-Llama-3-8B-Instruct-4bit\"\n",
    "    model, tokenizer = load(model_name)\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Prompt for ontology input: local file or URL\n",
    "    ontology_choice = input(\"Enter 1 for local ontology file or 2 for ontology URL: \").strip()\n",
    "    if ontology_choice == \"1\":\n",
    "        ontology_source = input(\"Enter the path to your ontology file (e.g., COPPER2.rdf): \").strip()\n",
    "    elif ontology_choice == \"2\":\n",
    "        ontology_source = input(\"Enter the URL to your ontology file: \").strip()\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Prompt for the target classes CSV file and base IRI\n",
    "    target_csv = input(\"Enter the path to your target classes CSV file (e.g., hboRR.csv): \").strip()\n",
    "    base_iri = input(\"Enter the base IRI of the ontology to be searched (e.g., http://COPPER/ontology/COPPER_): \").strip()\n",
    "\n",
    "    # Extract all class definitions from the ontology\n",
    "    all_defs = extract_class_definitions(ontology_source, base_iri)\n",
    "\n",
    "    # Read target classes from the CSV\n",
    "    target_classes = read_target_classes_from_csv(target_csv)\n",
    "\n",
    "    # Process each target class\n",
    "    all_matches = []\n",
    "    for target_class in target_classes:\n",
    "        filtered_defs = prefilter_classes(target_class, all_defs, embedder)\n",
    "        prompts = create_prompt_for_class(target_class, filtered_defs)\n",
    "        similar_matches = process_prompts(prompts, model, tokenizer)\n",
    "        all_matches.extend(similar_matches)\n",
    "\n",
    "    print(f\"Total number of matches found: {len(all_matches)}\")\n",
    "    \n",
    "    # Display results in a table in the console\n",
    "    results_df = display_results_table(all_matches)\n",
    "    \n",
    "    # Write CSV file\n",
    "    csv_filename = \"matchingDefinitions.csv\"\n",
    "    write_results_to_csv(all_matches, filename=csv_filename)\n",
    "    \n",
    "    # Provide a download link using base64 encoding\n",
    "    csv_data = results_df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "    download_html = f'<a href=\"data:file/csv;base64,{b64}\" download=\"{csv_filename}\">Download CSV File</a>'\n",
    "    display(HTML(download_html))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
